# ðŸ¦œðŸ”— LangChain Learning Modules

Welcome to the LangChain Learning Repository! This project is structured into six core modules that represent the fundamental building blocks of LangChain. Each folder explores a different aspect of LangChain through simple, focused examples.

## ðŸ“š Modules

1. **Models**
   - Learn how to load and use language models with LangChain.
   - Covers: `ChatOpenAI`, `LLM`, temperature, and model configuration.

2. **Prompts**
   - Understand how to structure prompts and parse outputs.
   - Covers: `PromptTemplate`, `FewShotPromptTemplate`, `StructuredOutputParser`, and more.

3. **Chains**
   - Combine models and prompts into logical pipelines.
   - Covers: `LLMChain`, `SimpleSequentialChain`, `TransformChain`.

4. **Indexes**
   - Learn how to create and query indexes for documents.
   - Covers: `VectorStoreIndex`, `RetrievalQA`, `FAISS`, `Chroma`.

5. **Memory**
   - Add conversational memory to your applications.
   - Covers: `ConversationBufferMemory`, `ConversationSummaryMemory`, and memory-aware chains.

6. **Agents**
   - Build autonomous agents that use tools to reason and act.
   - Covers: `AgentExecutor`, `Tool`, `ZeroShotAgent`, and custom tools.

---

## ðŸ§  Structured Outputs

Structured outputs are handled in the **Prompts** module, using tools like:
- `StructuredOutputParser`
- `PydanticOutputParser`
- `ResponseSchema`

These tools define how model outputs are parsed into structured formats such as Python dicts or custom classes.

---

## ðŸš€ Getting Started

1. Clone the repo:
   ```bash
  to be added
